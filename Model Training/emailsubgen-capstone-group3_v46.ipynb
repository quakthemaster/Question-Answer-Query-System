{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-07-17T01:13:11.811493Z","iopub.status.busy":"2023-07-17T01:13:11.811091Z","iopub.status.idle":"2023-07-17T01:13:11.824003Z","shell.execute_reply":"2023-07-17T01:13:11.822738Z","shell.execute_reply.started":"2023-07-17T01:13:11.811462Z"},"trusted":true},"outputs":[],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load\n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the read-only \"../input/\" directory\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","\n","# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n","# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:13:13.849755Z","iopub.status.busy":"2023-07-17T01:13:13.849384Z","iopub.status.idle":"2023-07-17T01:13:14.17735Z","shell.execute_reply":"2023-07-17T01:13:14.176241Z","shell.execute_reply.started":"2023-07-17T01:13:13.849726Z"},"trusted":true},"outputs":[],"source":["df = pd.read_csv(\"{path to train file}\")\n","df_val = pd.read_csv(\"{path to val file}\")\n","df_test = pd.read_csv(\"{path to test file}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:13:15.960345Z","iopub.status.busy":"2023-07-17T01:13:15.959988Z","iopub.status.idle":"2023-07-17T01:14:42.24536Z","shell.execute_reply":"2023-07-17T01:14:42.244205Z","shell.execute_reply.started":"2023-07-17T01:13:15.960319Z"},"trusted":true},"outputs":[],"source":["!pip install -U transformers[torch]\n","!pip install -U huggingface_hub\n","! pip install evaluate\n","!pip install sacrebleu\n","!pip install rouge_score\n","!pip install -U nltk\n","#!pip install bitsandbytes"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:14:42.249287Z","iopub.status.busy":"2023-07-17T01:14:42.248607Z","iopub.status.idle":"2023-07-17T01:14:55.135257Z","shell.execute_reply":"2023-07-17T01:14:55.134131Z","shell.execute_reply.started":"2023-07-17T01:14:42.249253Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, random_split, DataLoader\n","from transformers import GPT2Tokenizer, TrainingArguments, Trainer, GPT2LMHeadModel, DataCollatorForLanguageModeling #Seq2SeqTrainingArguments, Seq2SeqTrainer\n","import accelerate\n","import evaluate\n","#import bitsandbytes\n","from torch import nn\n","from transformers.trainer_pt_utils import get_parameter_names\n","import re"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:14:55.137951Z","iopub.status.busy":"2023-07-17T01:14:55.136591Z","iopub.status.idle":"2023-07-17T01:14:56.416332Z","shell.execute_reply":"2023-07-17T01:14:56.415217Z","shell.execute_reply.started":"2023-07-17T01:14:55.137914Z"},"trusted":true},"outputs":[],"source":["!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:14:56.421105Z","iopub.status.busy":"2023-07-17T01:14:56.419572Z","iopub.status.idle":"2023-07-17T01:14:58.975245Z","shell.execute_reply":"2023-07-17T01:14:58.974291Z","shell.execute_reply.started":"2023-07-17T01:14:56.421062Z"},"trusted":true},"outputs":[],"source":["sacrebleu = evaluate.load(\"sacrebleu\")\n","rouge = evaluate.load(\"rouge\")\n","meteor = evaluate.load(\"meteor\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:14:58.977323Z","iopub.status.busy":"2023-07-17T01:14:58.976558Z","iopub.status.idle":"2023-07-17T01:14:58.990693Z","shell.execute_reply":"2023-07-17T01:14:58.989527Z","shell.execute_reply.started":"2023-07-17T01:14:58.977296Z"},"trusted":true},"outputs":[],"source":["torch.manual_seed(42)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:14:58.992981Z","iopub.status.busy":"2023-07-17T01:14:58.992383Z","iopub.status.idle":"2023-07-17T01:15:10.582145Z","shell.execute_reply":"2023-07-17T01:15:10.580339Z","shell.execute_reply.started":"2023-07-17T01:14:58.99295Z"},"trusted":true},"outputs":[],"source":["tokenizer = GPT2Tokenizer.from_pretrained('distilgpt2', bos_token='<|startoftext|>',\n","                                          eos_token='<|endoftext|>', pad_token='<|pad|>', sep_token='<|sep|>')\n","model = GPT2LMHeadModel.from_pretrained('distilgpt2').cuda()\n","model.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:15:10.584583Z","iopub.status.busy":"2023-07-17T01:15:10.583604Z","iopub.status.idle":"2023-07-17T01:15:10.594672Z","shell.execute_reply":"2023-07-17T01:15:10.593228Z","shell.execute_reply.started":"2023-07-17T01:15:10.584543Z"},"trusted":true},"outputs":[],"source":["datacollator = DataCollatorForLanguageModeling(tokenizer = tokenizer, mlm=False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:15:10.596448Z","iopub.status.busy":"2023-07-17T01:15:10.596039Z","iopub.status.idle":"2023-07-17T01:15:11.954845Z","shell.execute_reply":"2023-07-17T01:15:11.952383Z","shell.execute_reply.started":"2023-07-17T01:15:10.59641Z"},"trusted":true},"outputs":[],"source":["class EmailSubjectDataset(Dataset):\n","    def __init__(self, data, tokenizer):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for index, row in data.iterrows():\n","            encodings_dict = tokenizer('<|startoftext|>' + row[\"Email\"] + '<|sep|>' + row[\"Subject\"] + '<|endoftext|>', truncation=True, max_length=250, padding=\"max_length\", return_tensors='pt')\n","            self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","            self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:15:11.964108Z","iopub.status.busy":"2023-07-17T01:15:11.962794Z","iopub.status.idle":"2023-07-17T01:15:12.046771Z","shell.execute_reply":"2023-07-17T01:15:12.043388Z","shell.execute_reply.started":"2023-07-17T01:15:11.96407Z"},"trusted":true},"outputs":[],"source":["class ValEmailSubjectDataset(Dataset):\n","    def __init__(self, data, tokenizer):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for index, row in data.iterrows():\n","          encodings_dict = tokenizer('<|startoftext|>' + row[\"Email\"] + '<|sep|>', truncation=True, max_length=250, padding=\"max_length\", return_tensors='pt')\n","          if((encodings_dict['input_ids'][0][249] != torch.Tensor(np.array([50259]))) and (encodings_dict['input_ids'][0][249] != torch.Tensor(np.array([50258])))):\n","            encodings_dict['input_ids'][0] = torch.cat((encodings_dict['input_ids'][0][np.r_[:249]],torch.Tensor(np.array([50258]))),0)\n","          self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","          self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:15:12.052559Z","iopub.status.busy":"2023-07-17T01:15:12.051842Z","iopub.status.idle":"2023-07-17T01:15:12.092939Z","shell.execute_reply":"2023-07-17T01:15:12.092023Z","shell.execute_reply.started":"2023-07-17T01:15:12.052522Z"},"trusted":true},"outputs":[],"source":["class TestEmailSubjectDataset(Dataset):\n","    def __init__(self, data, tokenizer):\n","        self.input_ids = []\n","        self.attn_masks = []\n","        self.labels = []\n","        for index, row in data.iterrows():\n","          encodings_dict = tokenizer('<|startoftext|>' + row[\"Email\"] + '<|sep|>', truncation=True, max_length=250, return_tensors='pt')\n","          self.input_ids.append(torch.tensor(encodings_dict['input_ids']))\n","          self.attn_masks.append(torch.tensor(encodings_dict['attention_mask']))\n","\n","    def __len__(self):\n","        return len(self.input_ids)\n","\n","    def __getitem__(self, idx):\n","        return self.input_ids[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T01:15:12.095221Z","iopub.status.busy":"2023-07-17T01:15:12.094215Z","iopub.status.idle":"2023-07-17T01:15:52.97085Z","shell.execute_reply":"2023-07-17T01:15:52.969995Z","shell.execute_reply.started":"2023-07-17T01:15:12.095188Z"},"trusted":true},"outputs":[],"source":["train_dataset = EmailSubjectDataset(df, tokenizer)\n","val_dataset = ValEmailSubjectDataset(df_val,tokenizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2023-07-16T08:14:06.561186Z","iopub.status.busy":"2023-07-16T08:14:06.56083Z","iopub.status.idle":"2023-07-16T08:14:06.57684Z","shell.execute_reply":"2023-07-16T08:14:06.575887Z","shell.execute_reply.started":"2023-07-16T08:14:06.56115Z"},"trusted":true},"outputs":[],"source":["training_args = TrainingArguments(\n","    output_dir=\"/kaggle/working/output\",\n","    overwrite_output_dir=True,\n","    num_train_epochs=15,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=16,\n","    #eval_steps = 2,\n","    eval_steps = 400,\n","    save_steps=800,\n","    warmup_steps=500,\n","    load_best_model_at_end=True,\n","    #evaluation_strategy=\"steps\",\n","    #save_strategy = \"steps\",\n","    evaluation_strategy=\"epoch\",\n","    save_strategy = \"epoch\",\n","    weight_decay=0.01,\n","    metric_for_best_model = \"rougeL\",\n","    gradient_accumulation_steps=4,\n","    gradient_checkpointing=True,\n","    fp16=True\n","    )"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2023-07-08T09:32:47.446795Z","iopub.status.busy":"2023-07-08T09:32:47.446454Z","iopub.status.idle":"2023-07-08T09:32:47.463689Z","shell.execute_reply":"2023-07-08T09:32:47.462684Z","shell.execute_reply.started":"2023-07-08T09:32:47.446764Z"}},"source":["decay_parameters = get_parameter_names(model, [nn.LayerNorm])\n","decay_parameters = [name for name in decay_parameters if \"bias\" not in name]\n","optimizer_grouped_parameters = [\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if n in decay_parameters],\n","        \"weight_decay\": training_args.weight_decay,\n","    },\n","    {\n","        \"params\": [p for n, p in model.named_parameters() if n not in decay_parameters],\n","        \"weight_decay\": 0.0,\n","    },\n","]\n","\n","optimizer_kwargs = {\n","    \"betas\": (training_args.adam_beta1, training_args.adam_beta2),\n","    \"eps\": training_args.adam_epsilon,\n","}\n","optimizer_kwargs[\"lr\"] = training_args.learning_rate\n","adam_bnb_optim = bitsandbytes.optim.Adam8bit(\n","    optimizer_grouped_parameters,\n","    betas=(training_args.adam_beta1, training_args.adam_beta2),\n","    eps=training_args.adam_epsilon,\n","    lr=training_args.learning_rate,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-16T08:14:06.578913Z","iopub.status.busy":"2023-07-16T08:14:06.578094Z","iopub.status.idle":"2023-07-16T08:14:06.59092Z","shell.execute_reply":"2023-07-16T08:14:06.589983Z","shell.execute_reply.started":"2023-07-16T08:14:06.578879Z"},"trusted":true},"outputs":[],"source":["def compute_metrics(eval_pred, eval_dataset, df):\n","    decoded_preds = []\n","    references = [df['Subject'], df['Ann0'], df['Ann1'], df['Ann2']]\n","    refs = []\n","    \n","    for i, sample_input in enumerate(eval_dataset):\n","        temp_input = sample_input[0][sample_input[0] !=torch.Tensor(np.array([50259]))]\n","        temp_input = temp_input[None, :]\n","        metric_outputs = model.generate(temp_input.cuda(), min_new_tokens = 4, max_new_tokens = 12, num_beams=5, early_stopping=True, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","        decoded_preds.append(tokenizer.decode(metric_outputs[0]))\n","    \n","    final_preds =[]\n","    for j in range(len(decoded_preds)):\n","        lst = decoded_preds[j].split('<|sep|>')\n","        if (len(lst) >= 2):\n","            final_preds.append(lst[1].replace(\"<|endoftext|>\",\"\"))\n","        temp_refs = []\n","        for k in range(len(references)):\n","            temp_refs.append(references[k][j])\n","        refs.append(temp_refs)\n","    \n","    results_sacrebleu = sacrebleu.compute(predictions=final_preds, references=refs, lowercase = True)\n","    \n","    results_rouge = rouge.compute(predictions=final_preds, references=refs)\n","    \n","    results_meteor = meteor.compute(predictions=final_preds, references=refs)\n","    \n","    return {'bleu': results_sacrebleu['score'], 'rouge1' : results_rouge['rouge1'], 'rouge2' : results_rouge['rouge2'], 'rougeL' : results_rouge['rougeL'], 'meteor' : results_meteor['meteor']}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-16T08:14:06.593196Z","iopub.status.busy":"2023-07-16T08:14:06.592367Z","iopub.status.idle":"2023-07-16T08:14:06.601217Z","shell.execute_reply":"2023-07-16T08:14:06.600181Z","shell.execute_reply.started":"2023-07-16T08:14:06.593163Z"},"trusted":true},"outputs":[],"source":["def preprocess_logits_for_metrics(logits, labels):\n","    \"\"\"\n","    Original Trainer may have a memory leak. \n","    This is a workaround to avoid storing too many tensors that are not needed.\n","    \"\"\"\n","    pred_ids = torch.argmax(logits, dim=-1)\n","    return pred_ids, labels"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-16T08:14:06.603114Z","iopub.status.busy":"2023-07-16T08:14:06.60264Z","iopub.status.idle":"2023-07-16T08:14:06.619431Z","shell.execute_reply":"2023-07-16T08:14:06.618569Z","shell.execute_reply.started":"2023-07-16T08:14:06.603084Z"},"trusted":true},"outputs":[],"source":["trainer = Trainer(model=model, args=training_args, train_dataset=train_dataset, eval_dataset=val_dataset, data_collator=datacollator, compute_metrics = lambda pred: compute_metrics(pred, val_dataset, df_val), preprocess_logits_for_metrics = preprocess_logits_for_metrics)#, optimizers=(adam_bnb_optim, None))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-16T08:14:06.621393Z","iopub.status.busy":"2023-07-16T08:14:06.620816Z","iopub.status.idle":"2023-07-16T08:14:10.034518Z","shell.execute_reply":"2023-07-16T08:14:10.033501Z","shell.execute_reply.started":"2023-07-16T08:14:06.621359Z"},"trusted":true},"outputs":[],"source":["# import wandb\n","# wandb.login(key = \"{your token here}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-16T08:14:10.038257Z","iopub.status.busy":"2023-07-16T08:14:10.037551Z","iopub.status.idle":"2023-07-16T08:30:42.669028Z","shell.execute_reply":"2023-07-16T08:30:42.667435Z","shell.execute_reply.started":"2023-07-16T08:14:10.038227Z"},"trusted":true},"outputs":[],"source":["trainer.train()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["trainer.save_model()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:52:55.415488Z","iopub.status.busy":"2023-07-17T00:52:55.414973Z","iopub.status.idle":"2023-07-17T00:52:59.654944Z","shell.execute_reply":"2023-07-17T00:52:59.653777Z","shell.execute_reply.started":"2023-07-17T00:52:55.415445Z"},"trusted":true},"outputs":[],"source":["#trainedmodel = GPT2LMHeadModel.from_pretrained(\"/kaggle/input/trainedmodel\").cuda()\n","#trainedmodel.resize_token_embeddings(len(tokenizer))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:39:34.353553Z","iopub.status.busy":"2023-07-17T00:39:34.353059Z","iopub.status.idle":"2023-07-17T00:39:39.120077Z","shell.execute_reply":"2023-07-17T00:39:39.118788Z","shell.execute_reply.started":"2023-07-17T00:39:34.353516Z"},"trusted":true},"outputs":[],"source":["test_dataset = TestEmailSubjectDataset(df_test,tokenizer)\n","len(test_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:53:00.415824Z","iopub.status.busy":"2023-07-17T00:53:00.4149Z","iopub.status.idle":"2023-07-17T00:56:24.683213Z","shell.execute_reply":"2023-07-17T00:56:24.682168Z","shell.execute_reply.started":"2023-07-17T00:53:00.415779Z"},"trusted":true},"outputs":[],"source":["temp_output = [] \n","for i, sample_input in enumerate(test_dataset):\n","    if(len(sample_input[0]) == 250 and sample_input[0][249] != torch.Tensor(np.array([50258]))):\n","        sample_input[0] = torch.cat((sample_input[0][np.r_[:249]],torch.Tensor(np.array([50258]))),0)\n","    sample_output = model.generate(sample_input.cuda(), min_new_tokens = 4, max_new_tokens = 12, num_beams=5, early_stopping=True, num_return_sequences=1, pad_token_id=tokenizer.eos_token_id)\n","    temp_output.append(tokenizer.decode(sample_output[0]))\n","final_output =[]\n","for j in range(len(temp_output)):\n","    lst = temp_output[j].split('<|sep|>')\n","    if (len(lst) >= 2):\n","        final_output.append(lst[1].replace(\"<|endoftext|>\",\"\"))\n","    else:\n","        final_output.append(\"\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:56:24.685767Z","iopub.status.busy":"2023-07-17T00:56:24.685373Z","iopub.status.idle":"2023-07-17T00:56:24.775444Z","shell.execute_reply":"2023-07-17T00:56:24.774412Z","shell.execute_reply.started":"2023-07-17T00:56:24.685726Z"},"trusted":true},"outputs":[],"source":["df_test[\"Generated\"] = final_output\n","df_test.to_csv('/kaggle/working/Generated.csv')"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["#df_test = pd.read_csv(\"/kaggle/input/generatedoutput/Generated.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:56:24.777556Z","iopub.status.busy":"2023-07-17T00:56:24.777134Z","iopub.status.idle":"2023-07-17T00:56:24.784556Z","shell.execute_reply":"2023-07-17T00:56:24.783427Z","shell.execute_reply.started":"2023-07-17T00:56:24.777522Z"},"trusted":true},"outputs":[],"source":["pred = df_test['Generated']\n","ref = [df_test['Subject'], df_test['Ann0'], df_test['Ann1'], df_test['Ann2']]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:56:24.78899Z","iopub.status.busy":"2023-07-17T00:56:24.78826Z","iopub.status.idle":"2023-07-17T00:56:24.801019Z","shell.execute_reply":"2023-07-17T00:56:24.799829Z","shell.execute_reply.started":"2023-07-17T00:56:24.788914Z"},"trusted":true},"outputs":[],"source":["def score_evaluate(predictions, references):\n","    preds = []\n","    refs = []\n","    for i in range(len(predictions)):\n","        preds.append(predictions[i])\n","        temp_refs = []\n","        for j in range(len(references)):\n","            temp_refs.append(references[j][i])\n","        refs.append(temp_refs)\n","    results_sacrebleu = sacrebleu.compute(predictions=preds, references=refs, lowercase = True)\n","    print(\"Bleu Score : \" + str(results_sacrebleu['score']))\n","\n","    results_rouge = rouge.compute(predictions=preds, references=refs)\n","    print(\"Rouge1 Score : \" + str(results_rouge['rouge1']))\n","    print(\"Rouge2 Score : \" + str(results_rouge['rouge2']))\n","    print(\"RougeL Score : \" + str(results_rouge['rougeL']))\n","\n","    results_meteor = meteor.compute(predictions=preds, references=refs)\n","    print(\"Meteor Score : \" + str(results_meteor['meteor']))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2023-07-17T00:56:24.803265Z","iopub.status.busy":"2023-07-17T00:56:24.802827Z","iopub.status.idle":"2023-07-17T00:56:33.036074Z","shell.execute_reply":"2023-07-17T00:56:33.035049Z","shell.execute_reply.started":"2023-07-17T00:56:24.80323Z"},"trusted":true},"outputs":[],"source":["score_evaluate(pred,ref)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
